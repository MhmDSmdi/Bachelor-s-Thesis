\chapter{پیشینه تشخیص اخبار جعلی}
\section{کارهای انجام شده در زبان انگلیسی}
با رشد چشم‌گیر استفاده از الگوریتم‌های یادگیری ماشین و شبکه‌های عصبی عمیق در پردازش زبان طبیعی، تحقیقات و طرح‌های بسیاری در زمینه تشخیص اخبار کذب انجام شده ‌است. در ادامه به پژوهش‌های مرتبط انجام‌شده اشاره کرده و سپس در بخش بعد، مجموعه داده‌های موجود در زبان انگلیسی را مرور می‌کنیم.

\citet{ahmed2017detection}\LTRfootnote{\citeauthor*{ahmed2017detection}} با استفاده از تحلیل و بررسی متن به‌وسیله روش مبتنی ‌بر چندتایی\LTRfootnote{N-gram} و نمایش برداری مبتنی‌ بر بسامد واژه-معکوس بسامد سند\LTRfootnote{Term Frequency - Inverse Document Frequency (tf-idf)} از الگوریتم‌های متداول یادگیری ماشین مانند ماشین بردار پشتیبان\LTRfootnote{Support Vector Machine (SVM)}، ماشین بردار پشتیبان خطی\LTRfootnote{Linear Support Vector Machine (LSVM)}، نزدیک‌ترین همسایه\LTRfootnote{Nearest Neighbor}، درخت تصمیم\LTRfootnote{Decision Tree}، گرادیان کاهشی تصادفی\LTRfootnote{Stochastic Gradient Descent (SGD)} و رگرسیون لجستیک\LTRfootnote{Logistic Regression} برای تشخیص اخبار جعلی استفاده کرده‌اند. با ایجاد ترکیب‌های متفاوت از توالی واژه‌ها به‌صورت تکی و دوتایی و غیره، اطلاعات آماری هر ترکیب را با استفاده از روش مبتنی‌ بر واژه برای اخبار جعلی مجموعه یادگیری شامل اخبار جعلی و اصیل بازنمایی کردند. %با انجام آزمایش‌ها، بهترین نتیجه با استفاده از الگوریتم ماشین بردار پشتیبان خطی با دقت $92$ درصد، به‌دست آمد.

\citet{zhang2020fakedetector}\LTRfootnote{\citeauthor*{zhang2020fakedetector}} یک سامانه با عنوان «تشخیص‌دهنده جعل»\LTRfootnote{Fake Detector} را پیاده‌سازی  کردند که از دو بخش اصلی تشکیل شده ‌است: «یادگیری ویژگی بازنمایی»  \LTRfootnote{Representation Feature Learning} و «استخراج ویژگی صریح»\LTRfootnote{Explicit Feature Extraction}. در کنار هر خبر، اطلاعات اجتماعی متنوعی مرتبط با آن خبر وجود دارد که مدل‌سازی در آن توسط یک واحد یادگیرنده ویژگی انجام می‌پذیرد. این قسمت، علاوه بر یادگیری ویژگی‌های آشکار مرتبط با  عنوان یک خبر، مانند گروهی از واژه‌های استفاده‌شده، دارای بخش دیگری برای یادگیری ویژگی‌های نهان یک خبر، مانند ویژگی‌های مرتبط با موضوع و یا نویسنده آن خبر، است. علاوه بر این واحد یادگیرنده ویژگی، یک واحد پردازشی برای ایجاد ارتباط مناسب میان بردارهای مختلف متن خبر، عنوان خبر و موضوع خبر به‌نام «واحد انتشار دروازه‌ای»\LTRfootnote{Gated Diffusive Unit (GDU)} نیز در معماری این مدل استفاده شده‌است. این واحد پردازشی، امکان استفاده از چندین ورودی متنوع را به‌صورت همزمان ایجاد می‌نماید.

در پژوهشی که توسط \citet{ramezani2019news} انجام شده ‌است، آنان با استفاده از «شبکه‌های عصبی بازگشتی»\LTRfootnote{Recurrent Neural Network (RNN)} و معرفی یک «تابع هزینه»\LTRfootnote{Loss function} جدید، سعی کرده‌اند تا دنباله اخبار را به‌صورت یک پیوستار زمانی بررسی کنند و در هر مقطع زمانی با یک احتمال، برچسب خبر را مشخص کنند. با گذر زمان و دریافت اطلاعات بیشتر، دقت برچسب یک خبر دقیق‌تر خواهد شد. همچنین در تابع هزینه معرفی‌شده، پارامتر زمان نیز مؤثر است؛ به این دلیل که هدف، برچسب‌گذاری دقیق در سریع‌ترین زمان ممکن است تا از انتشار گسترده خبر جعلی به‌سرعت جلوگیری شود. این پژوهش برروی دادگان جمع‌آوری‌شده از دو شبکه اجتماعی توییتر و «سینا ویبو»\LTRfootnote{Sina Weibo} آزمایش شده ‌است.

\citet{khattar2019mvae}\LTRfootnote{\citeauthor*{khattar2019mvae}}   از  «خودکدگذار وردشی»\LTRfootnote{Variational Autoencoder (VA)} استفاده کردند تا اخبار جعلی را تشخیص دهند. برای این کار از مجموعه داده توییتر استفاده کردند که شامل یک بخش متن و یک عکس به‌همراه آن است. مدل آنها از سه بخش کدگذارِ\LTRfootnote{Encoder} متن و تصویر، کدگشای\LTRfootnote{Decoder} متن و تصویر و تشخیص‌دهنده خبر جعلی تشکیل شده‌ است. بخش کدگذار، خود شامل یک شبکه عصبی بازگشتی برای استخراج ویژگی‌های متنی و یک «شبکه عصبی پیچشی»\LTRfootnote{Convolutional Neural Network (CNN)} برای استخراج ویژگی‌های مرتبط با عکس است. سپس، ویژگی‌های نهان استخراج‌شده از دو منبع عکس و متن، «بردار نهان»\LTRfootnote{Latent Vector} اصلی را شکل می‌دهد. مجموعه کدگذار و کدگشا در فرایند یادگیری، ویژگی‌های نهان اخبار جعلی را با توجه به متن و عکس‌ها یاد می‌گیرد؛ و پس از آن با استفاده از این ویژگی‌های نهان توسط بخش تشخیص‌دهنده، جعلی‌بودن آن را تشخیص می‌دهد.  %دقت نهایی به‌دست‌آمده برای دادگان توییتر و ویبو به ترتیب $74.5$ و $82.4$ درصد بوده‌است. 

\citet{yang2019unsupervised}\LTRfootnote{\citeauthor*{yang2019unsupervised}} برای تشخیص اخبار جعلی از روش یادگیری «بدون نظارت»\LTRfootnote{Unsupervised learning} استفاده کرده‌اند که در آن با استفاده از  یک مدل احتمالاتی گرافیکی، صحت اخبار و اعتبار کاربران مدل شده‌ است. آنها با استفاده از ویژگی‌های نهان به‌دست‌آمده برای  کاربر و خبر مورد نظر توسط روش نمونه‌برداری گیبز\LTRfootnote{Gibbs sampling} کار دسته‌بندی خبر جعلی را انجام می‌دهند. این روش بر روی دو مجموعه داده لیار\LTRfootnote{Liar}  \citep{wang2017liar}\LTRfootnote{\citeauthor*{wang2017liar}}  و بازفیدنیوز\LTRfootnote{https://github.com/BuzzFeedNews/2016-10-facebook-fact-check} آزمایش شده‌ است. %که به‌ترتیب دقت \%$75.9$ و \%$67.9$ به‌دست آمده‌است.

\citet{liu2019two}\LTRfootnote{\citeauthor*{liu2019two}} یک مدل دومرحله‌ای براساس مدل برت\LTRfootnote{BERT} ارائه کرده‌اند که با استفاده از تعبیه اطلاعات فراداده مانند نام
 گوینده، شغل و غیره به‌همراه متن اصلی، خبر جعلی تشخیص داده می‌شود. در این مدل، به‌جای استفاده از اولین بردار خروجی مدل برت که نماینده تمام جمله است، از تمامی بردارهای خروجی برای کلمات استفاده می‌شود تا با به‌کارگیری روش توجه، برای
 هرکدام یک وزن محاسبه شود. مرحله اول این مدل، به طبقه‌بندی کلی اخبار جعلی و درست می‌پردازد و با استفاده از بردارهای خروجی این مرحله، در مرحله دوم با دسته‌بندی جزئی‌تر، اخبار دسته‌بندی می‌شود. این مدل برروی دادگان لیار به دو صورت دسته‌بندی دوتایی و دسته‌بندی چندتایی آزمایش شده است.%و دقت \%$29.07$ را بدون استفاده از اطلاعات فراداده و دقت \%$40.58$ را با استفاده از اطلاعات فراداده به‌دست آورده‌است.

\citet{jwa2019exbake}\LTRfootnote{\citeauthor*{jwa2019exbake}} .با استفاده از پیکره اخبار از خبرگزاری سی.ان.ان\LTRfootnote{CNN} و  «دیلی میل»\LTRfootnote{Daily Mail} مدل برت را آموزش داده‌اند و از دادگان مرحله اول مسابقه اخبار جعلی\LTRfootnote{fakenewschallenge.org} (اف.ان.سی.وان\LTRfootnote{FNC-1}) برای «تنظیم دقیق»\LTRfootnote{Fine tune} مدل استفاده کرده‌اند. در این مدل از تابع «آنتروپی متقاطع وزن‌دار»\LTRfootnote{Weighted Cross-entropy} برای محاسبه خطا استفاده شده‌ است تا مشکل متوازن نبودن داده‌ها حل شود. در این پژوهش، دو مدل برای تشخیص خبر جعلی ارائه شده ‌است که در یک مدل از مدل آماده برت به‌همراه تابع آنتروپی متقاطع وزن‌دار استفاده شده و در مدل دیگر با استفاده از پیکره اخبار، مدل برت را آموزش داده‌اند. %همچنین نتایج آزمایش این دو مدل بر اساس معیار سنجش اف۱\LTRfootnote{F1-Score} به ترتیب برابر با  \%$73.4$ و \%$74.6$ است.

\cite{goldani2020detecting} دو شبکه کپسولی\LTRfootnote{Capsules Network} متفاوت برای تشخیص اخبار جعلی با طول‌های متفاوت ارائه کرده‌اند. به‌منظور دسته‌بندی اخبار جعلی متوسط و یا طولانی از ۴ شبکه موازی و برای اخبار کوتاه از ۲ شبکه موازی با اندازه صافی\LTRfootnote{Filter}  متفاوت به‌منظور استخراج ویژگی‌های سطح بالا در متن استفاده کردند. پس از استخراج ویژگی‌های سطح بالا، هر شبکه به یک لایه چگال\LTRfootnote{Dense} متصل شده‌است و درنهایت با استفاده از یک لایه میانگین ادغام\LTRfootnote{Average Pooling} احتمال جعلی‌بودن خبر را مشخص می‌کنند. %دقت این روش برروی دادگان آی.اس.اُ.تی. \%$99.8$ و برروی دادگان لیار با دسته‌بندی ۶ برچسب، \%$39.5$ بوده‌است.

\citet{kaliyar2020fndnet}\LTRfootnote{\citeauthor*{kaliyar2020fndnet}} یک شبکه عصبی عمیق پیچشی را با نام اف.ان.دی.نت\LTRfootnote{FNDNET} برای تشخیص اخبار جعلی ارائه کردند. در این مدل برای بازنمایی اخبار از مدل بازنمایی «بردار سراسری»\LTRfootnote{Global Vectors (GloVe)}  \citep{pennington2014glove}\LTRfootnote{\citeauthor*{pennington2014glove}} استفاده کردند. معماری این مدل شامل لایه‌های پیچشی که به‌صورت آبشاری قرار گرفته‌ است، می‌شود‌ تا ویژگی‌های مناسبی را برای اخبار تولید کند. درنهایت با استفاده از لایه‌های چگال، احتمال تعلق هر خبر به دسته جعلی یا اصیل مشخص می‌شود. به‌منظور ارزیابی مدل ارائه‌شده، آنها از دادگان وبگاه کگل\LTRfootnote{Kaggle} که مربوط به انتخابات سال ۲۰۱۶ آمریکا است استفاده کردند. % و دقت \%$98.36$ را ثبت کردند.
 
\section{دادگان موجود در انگلیسی و آمار دادگان}
در زبان انگلیسی دادگان زیادی برای تشخیص اخبار جعلی معرفی شده که از رسانه‌های اجتماعی یا وبگاه‌های خبری استخراج شده است. \tablename~\ref{englishDataset} به‌صورت مختصر فهرستی از دادگان موجود برای زبان انگلیسی را ارائه می‌دهد. در این جدول، ستون «داده و فراداده‌ها» نمایانگر اطلاعات و فراداده‌های اصلی موجود در هر یک از این دادگان است. 
عبارات \verb|PI|، \verb|TS|، \verb|UI|، \verb|T| به‌ترتیب به معنای اطلاعات مرتبط با انتشار خبر، برچسب زمانی، ویژگی مرتبط با اطلاعات کاربر و متن خبر است.
\begin{table}[!h]
\caption{آمار و اطلاعات مرتبط با دادگان شایعات در شبکه‌های اجتماعی \citep{li2019rumor}}
\label{englishDataset}
\begin{center}
\begin{tabular}{|M{5.5cm}|M{1.8cm}|M{2cm}|M{1.3cm}|M{2.5cm}|}
\hline
\textbf{مرجع} & \textbf{منبع} & \textbf{داده و فراداده‌ها} & \textbf{تعداد خبر}‌ & \textbf{عنوان مجموعه داده} \\
\hline
\hline
\citet{zubiaga2016pheme} & توییتر &
 \lr{PI/TS/UI/T} &
$330$ & \lr{PHEME-R} \\ 
\hline
\citet{kochkina2018pheme} & توییتر &
 \lr{PI/TS/UI/T} & 
$6,425$ & \lr{PHEME} \\
\hline
\citet{ma2016detecting} & توییتر &
 \lr{TS/UI/T} &
$992$ & \lr{Ma-Twitter} \\
\hline
\citet{ma2016detecting} & ویبو & 
\lr{TS/UI/T} &
$4664$ & \lr{Ma-Weibo} \\ 
\hline
\citet{ma2017detect} & توییتر & 
\lr{PI/TS/UI/T} &
$14,90$ & \lr{Twitter15} \\ 
\hline
\citet{ma2017detect} & توییتر &
 \lr{PI/TS/UI/T} & 
$818$ & \lr{Twitter16} \\ 
\hline
دادگان فعالیت ۷ مسابقه «ارزیابی معنایی» سال ۲۰۱۹ & توییتر، ردیت & 
\lr{PI/TS/UI/T} &
$325$ & \lr{SemEval19} \\
\hline

شایعات کگل براساس سایت اسناپس & توییتر، فیسبوک & 
\lr{T} &
$16,900$ & \lr{Kaggle Snopes} \\ 
\hline

\citet{tacchini2017some} & فیسبوک & 
\lr{TS/UI/T} &
$15,500$ & \lr{Facebook Hoax} \\ 
\hline

شایعات کگل براساس سایت پولیتی‌فکت & توییتر &
\lr{PI/TS/UI/T} &
$2,923$ & \lr{Kaggle PolitiFact} \\ 
\hline

\citet{shu2020fakenewsnet} & توییتر & 
\lr{PI/TS/UI/T} &
$23,196$ & \lr{FakeNewsNet} \\ 
\hline

\end{tabular}
\end{center}
\end{table}


با توجه به گسترش پژوهش فعالیت‌های تشخیص اخبار جعلی در سال‌های اخیر و تعداد زیاد دادگان این حوزه، در این پژوهش مجموعه‌دادگان لیار و آی.اس.اُ.تی.\LTRfootnote{ISOT} به‌عنوان نمونه‌های مطرح دادگان اخبار جعلی مورد مطالعه قرار گرفته‌است که ویژگی‌های این دو مجموعه داده اصلی به همراه دو مجموعه پرکاربرد دیگر در این حوزه در ادامه توضیح داده می‌شود.

\subsection{دادگان لیار}

\noindent \citet{wang2017liar} دادگانی با نام «لیار» برای تشخیص خبر کذب به زبان انگلیسی معرفی کردند. در این مجموعه هر خبر شامل 14 فراداده است، ازجمله شماره خبر، متن خبر، عنوان خبر، گوینده خبر، شغل گوینده، شهر، حزب و اطلاعات زمینه‌ای و 5 ویژگی مربوط به اعتبار گزاره‌های قبلی. هر خبر نیز دارای یک برچسب از مجموعه 6 تایی است که این برچسب‌ها عبارتند از: درست، نیمه درست، عمدتاً درست، جعلی، دروغ و به‌سختی درست. تعداد کل اخبار $12,788$ خبر می‌باشد که در 3 دسته داده آموزشی\LTRfootnote{Train set}، داده اعتبارسنجی\LTRfootnote{Validation set}، داده ارزیابی\LTRfootnote{Test set} تقسیم شده‌ است. همچنین باتوجه‌به این که «حزب» خبر یکی از فراداده‌های موجود در این مجموعه دادگان است، فراوانی 3 «حزب» دموکرات، جمهوری خواه و بی‌طرف به‌ترتیب 
$4,150$، $5,687$ و $2,185$ 
خبر است.
\tablename~\ref{liarDataset} آمار کلی این مجموعه داده را نمایش می‌دهد.

\begin{table}[!h]
\caption{آمار و اطلاعات مربوط به دادگان لیار}
\label{liarDataset}
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{آماره} & \textbf{مقدار} \\
\hline
\hline
اندازه مجموعه آموزش
&   $10,269$  \\
\hline
 اندازی مجموعه اعتبارسنجی
 & $1,284$  \\
\hline
  اندازه مجموعه آزمون
  & $1,283$ \\
\hline
 میانگین طول خبر
 & $17.9$  \\
\hline

\end{tabular}
\end{center}
\end{table}


\subsection{دادگان آی.اس.اُ.تی}
مجموعه داده «آی.اس.اُ.تی.» شامل اخبار اصیل و جعلی است که توسط \citet{ahmed2017detection} تهیه شده‌است.
$21,417$ خبر اصیل آن از وبگاه خبری رویترز و $23,481$ خبر جعلی از وبگاه‌های پولیتی‌فکت و ویکی‌پدیا جمع‌آوری و برچسب‌گذاری شده‌ است. در این مجموعه، هر خبر علاوه‌بر عنوان خبر و متن خبر، دارای 2  فراداده تاریخ خبر و موضوع خبر نیز 
می‌باشد. \tablename~\ref{ISOTDataset} آمار اخبار موجود در این مجموعه داده را به تفکیک اخبار اصیل و جعلی نمایش می‌دهد.

\begin{table}[!h]
\caption{آمار و اطلاعات مربوط به دادگان آی.اس.ا.ُتی}
\label{ISOTDataset}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
خبر & 
تعداد خبر & 
 نوع & 
 تعداد خبر
 \\
\hline
\hline
\multirow{2}{*}{اخبار اصیل} 
&
\multirow{2}{*}{$21,417$}
 &
  اخبار جهان\footnotemark
& $10,145$ 
\\ 
& 
&
 اخبار سیاسی\footnotemark
& 
$11,272$ \\ 
\hline
\multirow{6}{*}{اخبار جعلی}
 &
\multirow{6}{*}{$23,481$}
&
  اخبار دولت
& $1,570$
\\
& &
 خاورمیانه
& $778$ \\ 
& & 
اخبار آمریکا
& $783$ \\
& & 
اخبار چپ
& $4,459$ \\ 
& & 
سیاسی
& $6,841$ \\ 
& & 
دیگر
& $9,050$ \\ 
\hline

\end{tabular}
\end{center}
\end{table}
\LTRfootnotetext[56]{World-News}
\LTRfootnotetext[57]{Politics-News}

\subsection{دادگان بازفید}

\noindent
این دادگان شامل اخبار مرتبط با انتخابات آمریکا است که در فیسبوک\LTRfootnote{Facebook} منتشر شده بود.\LTRfootnote{https://www.buzzfeednews.com/article/craigsilverman/partisan-fb-pages-analysis}
این مجموعه شامل $2,283$ عنوان پست فیسبوک است که هر خبر از 12 فراداده مانند
 صفحه خبر، تاریخ، نوع محتوا، برچسب و اطلاعات مرتبط با میزان تأثیرگذاری بر کاربران مانند تعداد دفعات به اشتراک گذاشتن و
 تعداد نظرات و غیره تشکیل شده ‌است. \tablename~\ref{BuzzFeedDataset} آمار اخبار موجود در این مجموعه‌داده را نمایش می‌دهد.

\begin{table}[!h]
\caption{آمار و اطلاعات مربوط به دادگان بازفید}
\label{BuzzFeedDataset}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
حزب & بدون محتوای واقعی & عمدتاً درست & ترکیب درست و نادرست & عمدتاً نادرست & مجموع \\
\hline
\hline
چپ & 116 & 265 & 68 & 22 & 471 \\
\hline
جریان اصلی & 52 & $1,085$ & 8 & 0 & $1,145$ \\
\hline
راست & 96 & 319 & 169 & 82 & 666 \\
\hline
\end{tabular}
\end{center}
\end{table}


\subsection{توئیتر ۱۵}

\noindent
 \citet{ma2017detect} دادگانی از شبکه اجتماعی توییتر منتشر کردند که دارای 4 برچسب درست، نادرست، نامعتبر و غیرشایعه است. این پیام‌ها براساس سایت‌های
 اعتبارسنجی برچسب‌گذاری شده‌‌‌اند.  در این دادگان علاوه بر اطلاعات متن توییت‌ها، اطلاعات 276 هزار کاربر و شبکه ارتباط آن‌ها و همچنین نحوه بازنشر هر توییت مشخص  شده‌ است. جزئیات توزیع این برچسب‌ها در \tablename~\ref{Twitter15Dataset} آورده شده ‌است.

\begin{table}[!h]
\caption{آمار و اطلاعات مربوط به دادگان توییتر 15}
\label{Twitter15Dataset}
\begin{center}
\begin{tabular}{|M{4cm}|M{4cm}|}
\hline
برچسب & تعداد \\ 
\hline
\hline
غیرشایعه & 374 \\ \hline
نادرست & 370 \\ \hline
درست & 372 \\ \hline
نامعتبر & 374 \\ \hline
\end{tabular}
\end{center}
\end{table}

\section{دادگان موجود در سایر زبان‌ها}
با توجه به اهمیت موضوع تشخیص اخبار جعلی، در زبان‌هایی با منابع کم نیز پژوهش‌های زیادی در سال‌های اخیر بر روی اخبار  جعلی انجام شده‌است و مجموعه داده‌هایی برای اخبار جعلی در این زبان‌ها هم جمع‌آوری شده ‌است. \tablename~\ref{LowResourceDataset} به‌صورت مختصر لیستی از دادگان موجود برای اخبار جعلی برای سایر زبان‌ها را نمایش می‌دهد.

\begin{table}[!h]
\caption{لیست دادگان موجود در سایر زبان‌ها}
\label{LowResourceDataset}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
سال ارائه & داده & زبان ارائه \\ 
\hline \hline
\multirow{5}{*}{2019}
& \citep{vogel2019fake} & آلمانی \\ \cline{2-3}
& \citep{reyes2019detection} & اسپانیایی \\ \cline{2-3}
& \citep{vicario2019polarization} & ایتالیایی \\ \cline{2-3}
& \citep{liu2019detection} & فرانسوی \\ \cline{2-3}
& \citep{alkhair2019arabic} & عربی \\ \hline
2018 
& \citep{lozhnikov2018stance} & روسی \\ \hline
\end{tabular}
\end{center}
\end{table}

\section{کارهای انجام شده و دادگان موجود در زبان فارسی}
باتوجه‌به اینکه تمرکز اصلی این پروژه برروی تهیه دادگان فارسی و استانداردسازی داده به‌دست‌آمده برای کاربرد در سیستم تشخیص اخبار جعلی فارسی است، در این فصل مروری بر کارهای انجام شده در حوزه تشخیص اخبار جعلی فارسی ارائه می‌گردد و دادگان موجود در این حوزه معرفی می‌شود. در زبان فارسی پژوهشگرانی به صورت محدود در این حوزه فعالیت داشته‌اند و مجموعه دادگان انگشت‌شماری موجود است که در ادامه به معرفی آن‌ها می‌پردازیم.


\citet{zamani2017rumor} در دانشگاه تهران  با تمرکز برروی شبکه‌های اجتماعی به تحلیل و بررسی شایعات در توییتر پرداختند. در این پژوهش، با بهره‌گیری از اطلاعات مرتبط با شبکه ارتباطی کاربران و ویژگی‌های مرتبط با هر توییت به دسته‌بندی شایعات با استفاده از مدل‌های سنتی یادگیری ماشین پرداختند. علاوه بر تحلیل ویژگی‌های پراهمیت برای تشخیص شایعات در شبکه‌های اجتماعی، یک مجموعه داده در حوزه تشخیص شایعات توییتر ارائه دادند که شامل ۷۸۳ توییت جعلی و ۷۸۳ توییت اصیل است. به‌منظور استخراج شایعات از دو وب‌سایت ایرانی گمانه\LTRfootnote{https://gomaneh.net/} و شایعات\LTRfootnote{http://shayeaat.ir/} استفاده کردند.
در این پژوهش با استفاده از مدل‌های یادگیری ماشین مانند بیز ساده\LTRfootnote{Naive Bayes}، ماشین بردار پشتیبان\LTRfootnote{Support Vector Machine}، کا-نزدیک‌ترین همسایه\LTRfootnote{K Nearest Neighbor} و درخت تصمیم\LTRfootnote{Decision Tree} به دسته‌بندی این توییت‌ها براساس ویژگی‌های مرتبط با گراف کاربران و یا آماره‌های خود توئیت‌ها پرداختند.

\citet{mahmoodabad2018persian} در پژوهشی مجموعه دادگانی را با استفاده از بررسی پست‌های $11,981$ کاربر فارسی‌‌زبان در شبکه اجتماعی توییتر استخراج کردند.  این مجموعه‌داده شامل $3,593,704$ توییت فارسی است که عمدتاً در  مورد زلزله کرمانشاه بوده و با استفاده از سایت شایعات، برچسب‌گذاری کردند. مجموعه داده از نوامبر تا دسامبر 2017 جمع‌آوری شده و شامل $4,345$ توییت‌ شایعه است.
%
به دلیل نامتوازن ‌بودن اخبار شایعه و واقعی با استفاده از الگوریتم بیش نمونه‌برداری \lr{SMOTE}، آنها داده‌ها را متوازن کرده و سپس هر توئیت را با برداری شامل اطلاعات زمینه‌ای، اطلاعات ساختاری و اطلاعات جمعیتی بازنمائی کردند. در نهایت داده‌ها با استفاده از الگوریتم‌های متداول یادگیری ماشین همچون بیز ساده، ماشین بردار پشتیبان، درخت تصمیم و جنگل تصادفی\LTRfootnote{Random Forest} دسته‌بندی شدند.

\cite{zarharan2019persian}
با دیدگاه مبتنی بر روش دسته‌بندی موضع\LTRfootnote{Stance Classification} به تشخیص اخبار جعلی پرداخته‌اند.  
برای این منظور  ۵۳۴ ادعا به همراه  $2,124$ متن خبر در مورد آن ادعاها جمع‌آوری شد و سپس با استفاده از معماری یادگیری عمیق  حافظه کوتاه-مدت طولانی پشته‌ای\LTRfootnote{Stack LSTM} به دسته‌بندی رابطه میان ادعاها و متن‌های مرتبط با آن در ۴ کلاس موافق\LTRfootnote{Agree}، ناموافق\LTRfootnote{Disagree}، نامرتبط\LTRfootnote{Unrelated}، بحث‌شده\LTRfootnote{Discussed} پرداخته‌اند. ساختار این پژوهش مشابه پژوهش‌های انجام‌شده در زمینه تشخیص موضع\LTRfootnote{Stance Detection} در زبان انگلیسی بوده  و به دسته‌بندی اخبار براساس جعلی یا اصیل بودن نپرداخته ‌است.



\citet{jahanbakhsh2020model}  مجموعه دادگان دیگری با تمرکز برروی اخبار منتشر شده در شبکه‌ اجتماعی تلگرام منتشر کردند. این مجموعه داده شامل ۸۸۲ شایعه و ۸۸۲ پست اصیل است که از کانال‌ خبرگزاری‌هایی مانند: خبرگزاری فارس، دانشجویان ایران (ایسنا)، تسنیم، مهر و خبرگزاری جمهوری اسلامی (ایرنا) و همچنین سه وب‌سایت گمانه، ویکی هواکس\LTRfootnote{https://wikihoax.org/} و شایعات خزش شده‌اند.
% 
در پژوهش انجام شده توسط 
\citet{jahanbakhsh2020model} 
از مدل ارائه‌شده توسط 
\citet{allport1947psychology}
الهام گرفته شده‌است. در این مدل  یک رابطه به‌عنوان قدرت شایعه معرفی شده‌است  که ارتباط مستقیمی با اهمیت خبر و ابهام آن دارد. با توجه به این مقاله، 
\citet{jahanbakhsh2020model} 
به پیاده‌سازی مدلی برای محاسبه این ضریب، تحت عنوان قدرت انتشار شایعه در زبان فارسی پرداختند. برای محاسبه این ضریب از ویژگی‌های مانند احساس خبر، اهمیت خبر و ابهام خبر استفاده شده‌است.
جدول \ref{table.other_datasets} خلاصه‌ای از دادگان موجود زبان فارسی را نمایش می‌دهد.

\begin{table}[!h]
	\caption{آمار دادگان موجود فارسی}
	\label{table.other_datasets}
	\normalsize
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			مقاله & تعداد داده جعلی & تعداد کل داده & منبع اخبار جعلی & منبع اخبار \\
			\hline
			\hline
			\cite{jahanbakhsh2020model} & 
			882 & $1,764$ & ویکی هواکس / گمانه / شایعات & تلگرام \\
			\hline
			\cite{zarharan2019persian} & 
			600 & $2,124$ & شایعات / فیک‌نیوز & وب‌سایت‌ها \\
			\hline
			\cite{mahmoodabad2018persian} & 
			$4,345$ & $3,598,049$ & شایعات & توئیتر \\
			\hline
			\cite{zamani2017rumor} & 
			783 & $1,566$ & شایعات / گمانه & توئیتر \\
			\hline
			
		\end{tabular}
	\end{center}
\end{table}